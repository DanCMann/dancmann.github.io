<!DOCTYPE html>
<html xmlns="http://www.w3.org/1999/xhtml" lang="en" xml:lang="en"><head>

<meta charset="utf-8">
<meta name="generator" content="quarto-1.2.313">

<meta name="viewport" content="width=device-width, initial-scale=1.0, user-scalable=yes">


<title>Dan C. Mann, PhD – publications</title>
<style>
code{white-space: pre-wrap;}
span.smallcaps{font-variant: small-caps;}
div.columns{display: flex; gap: min(4vw, 1.5em);}
div.column{flex: auto; overflow-x: auto;}
div.hanging-indent{margin-left: 1.5em; text-indent: -1.5em;}
ul.task-list{list-style: none;}
ul.task-list li input[type="checkbox"] {
  width: 0.8em;
  margin: 0 0.8em 0.2em -1.6em;
  vertical-align: middle;
}
</style>


<script src="../site_libs/quarto-nav/quarto-nav.js"></script>
<script src="../site_libs/quarto-nav/headroom.min.js"></script>
<script src="../site_libs/clipboard/clipboard.min.js"></script>
<script src="../site_libs/quarto-search/autocomplete.umd.js"></script>
<script src="../site_libs/quarto-search/fuse.min.js"></script>
<script src="../site_libs/quarto-search/quarto-search.js"></script>
<meta name="quarto:offset" content="../">
<script src="../site_libs/quarto-html/quarto.js"></script>
<script src="../site_libs/quarto-html/popper.min.js"></script>
<script src="../site_libs/quarto-html/tippy.umd.min.js"></script>
<script src="../site_libs/quarto-html/anchor.min.js"></script>
<link href="../site_libs/quarto-html/tippy.css" rel="stylesheet">
<link href="../site_libs/quarto-html/quarto-syntax-highlighting.css" rel="stylesheet" id="quarto-text-highlighting-styles">
<script src="../site_libs/bootstrap/bootstrap.min.js"></script>
<link href="../site_libs/bootstrap/bootstrap-icons.css" rel="stylesheet">
<link href="../site_libs/bootstrap/bootstrap.min.css" rel="stylesheet" id="quarto-bootstrap" data-mode="light">
<script id="quarto-search-options" type="application/json">{
  "location": "navbar",
  "copy-button": false,
  "collapse-after": 3,
  "panel-placement": "end",
  "type": "overlay",
  "limit": 20,
  "language": {
    "search-no-results-text": "No results",
    "search-matching-documents-text": "matching documents",
    "search-copy-link-title": "Copy link to search",
    "search-hide-matches-text": "Hide additional matches",
    "search-more-match-text": "more match in this document",
    "search-more-matches-text": "more matches in this document",
    "search-clear-button-title": "Clear",
    "search-detached-cancel-button-title": "Cancel",
    "search-submit-button-title": "Submit"
  }
}</script>


<link rel="stylesheet" href="../styles.css">
</head>

<body class="nav-fixed">

<div id="quarto-search-results"></div>
  <header id="quarto-header" class="headroom fixed-top">
    <nav class="navbar navbar-expand-lg navbar-dark ">
      <div class="navbar-container container-fluid">
      <div class="navbar-brand-container">
    <a class="navbar-brand" href="../index.html">
    <span class="navbar-title">Dan C. Mann, PhD</span>
    </a>
  </div>
          <button class="navbar-toggler" type="button" data-bs-toggle="collapse" data-bs-target="#navbarCollapse" aria-controls="navbarCollapse" aria-expanded="false" aria-label="Toggle navigation" onclick="if (window.quartoToggleHeadroom) { window.quartoToggleHeadroom(); }">
  <span class="navbar-toggler-icon"></span>
</button>
          <div class="collapse navbar-collapse" id="navbarCollapse">
            <ul class="navbar-nav navbar-nav-scroll me-auto">
  <li class="nav-item">
    <a class="nav-link" href="../index.html">
 <span class="menu-text">Home</span></a>
  </li>  
  <li class="nav-item">
    <a class="nav-link" href="../qmd/research.html">
 <span class="menu-text">Academic Research</span></a>
  </li>  
  <li class="nav-item">
    <a class="nav-link" href="../qmd/teaching.html">
 <span class="menu-text">Teaching</span></a>
  </li>  
  <li class="nav-item">
    <a class="nav-link active" href="../qmd/publications.html" aria-current="page">
 <span class="menu-text">Publications</span></a>
  </li>  
  <li class="nav-item">
    <a class="nav-link" href="../qmd/posts.html">
 <span class="menu-text">Blog</span></a>
  </li>  
</ul>
              <div id="quarto-search" class="" title="Search"></div>
          </div> <!-- /navcollapse -->
      </div> <!-- /container-fluid -->
    </nav>
</header>
<!-- content -->
<div id="quarto-content" class="quarto-container page-columns page-rows-contents page-layout-article page-navbar">
<!-- sidebar -->
<!-- margin-sidebar -->
    <div id="quarto-margin-sidebar" class="sidebar margin-sidebar">
        <nav id="TOC" role="doc-toc" class="toc-active">
    <h2 id="toc-title">On this page</h2>
   
  <ul>
  <li><a href="#section" id="toc-section" class="nav-link active" data-scroll-target="#section">2022</a></li>
  <li><a href="#section-1" id="toc-section-1" class="nav-link" data-scroll-target="#section-1">2021</a></li>
  <li><a href="#section-2" id="toc-section-2" class="nav-link" data-scroll-target="#section-2">2020</a></li>
  <li><a href="#section-3" id="toc-section-3" class="nav-link" data-scroll-target="#section-3">2019</a></li>
  <li><a href="#section-4" id="toc-section-4" class="nav-link" data-scroll-target="#section-4">2012</a></li>
  </ul>
</nav>
    </div>
<!-- main -->
<main class="content" id="quarto-document-content">



<section id="section" class="level2">
<h2 class="anchored" data-anchor-id="section">2022</h2>
<p><a href="https://link.springer.com/article/10.1007/s10071-022-01735-0"><strong>Lessons learned in animal acoustic cognition through comparisons with humans.</strong></a></p>
<p>Marisa Hoeschele, Bernhard Wagner, <strong>Dan C. Mann</strong>. <em>Animal Cognition</em>. 2022</p>
<p><strong>Abstract</strong>: Humans are an interesting subject of study in comparative cognition. While humans have a lot of anecdotal and subjective knowledge about their own minds and behaviors, researchers tend not to study humans the way they study other species. Instead, comparisons between humans and other animals tend to be based on either assumptions about human behavior and cognition, or very different testing methods. Here we emphasize the importance of using insider knowledge about humans to form interesting research questions about animal cognition while simultaneously stepping back and treating humans like just another species as if one were an alien researcher. This perspective is extremely helpful to identify what aspects of cognitive processes may be interesting and relevant across the animal kingdom. Here we outline some examples of how this objective human-centric approach has helped us to move forward knowledge in several areas of animal acoustic cognition (rhythm, harmonicity, and vocal units). We describe how this approach works, what kind of benefits we obtain, and how it can be applied to other areas of animal cognition. While an objective human-centric approach is not useful when studying traits that do not occur in humans (e.g., magnetic spatial navigation), it can be extremely helpful when studying traits that are relevant to humans (e.g., communication). Overall, we hope to entice more people working in animal cognition to use a similar approach to maximize the benefits of being part of the animal kingdom while maintaining a detached and scientific perspective on the human species.</p>
</section>
<section id="section-1" class="level2">
<h2 class="anchored" data-anchor-id="section-1">2021</h2>
<p><a href="https://www.nature.com/articles/s41598-020-80340-y"><strong>Universal principles underlying segmental structures in parrot song and human speech</strong></a></p>
<p><strong>Dan C. Mann</strong>, W. Tecumseh Fitch, Hsiao-Wei Tu, Marisa Hoeschele. <em>Scientific Reports.</em> 2021.</p>
<p><strong>Abstract:</strong> Despite the diversity of human languages, certain linguistic patterns are remarkably consistent across human populations. While syntactic universals receive more attention, there is stronger evidence for universal patterns in the inventory and organization of segments: units that are separated by rapid acoustic transitions which are used to build syllables, words, and phrases. Crucially, if an alien researcher investigated spoken human language how we analyze non-human communication systems, many of the phonological regularities would be overlooked, as the majority of analyses in non-humans treat breath groups, or “syllables” (units divided by silent inhalations), as the smallest unit. Here, we introduce a novel segment-based analysis that reveals patterns in the acoustic output of budgerigars, a vocal learning parrot species, that match universal phonological patterns well-documented in humans. We show that song in four independent budgerigar populations is comprised of consonant- and vowel-like segments. Furthermore, the organization of segments within syllables is not random. As in spoken human language, segments at the start of a vocalization are more likely to be consonant-like and segments at the end are more likely to be longer, quieter, and lower in fundamental frequency. These results provide a new foundation for empirical investigation of language-like abilities in other species.</p>
</section>
<section id="section-2" class="level2">
<h2 class="anchored" data-anchor-id="section-2">2020</h2>
<p><a href="https://www.tandfonline.com/doi/abs/10.1080/09524622.2020.1718551?journalCode=tbio20"><strong>House finches learn canary trills</strong></a><br>
[Note! Unfortunately, this paper is not open access. Send me an <a href="mailto:danmann23@gmail.com">email</a> if you would like access.]</p>
<p><strong>Dan C. Mann</strong>, David C. Lahti, Laura Waddick, Paul C. Mundinger. <em>Bioacoustics.</em> 2020.</p>
<p><strong>Abstract:</strong> We analyse data from a cross-fostering experiment in which house finches were fostered by canary parents. Some individuals received canary song input, while others received no input, after a period of masking noise. We compare audio recordings of songs by these individuals to each other and to species-typical house finch and canary songs. Canary-tutored house finches learn to trill as part of their song. Since trills are not present in typical house finch song, naturally occurring song patterns underestimate what a species is capable of learning and producing. These results highlight a potential avenue for the origin of novel syntax in songbirds.</p>
<p><a href="https://www.researchgate.net/profile/Marisa-Hoeschele/publication/341107536_Segmental_units_in_nonhuman_animal_vocalization_as_a_window_into_meaning_structure_and_the_evolution_of_language/links/5eb43482299bf152d6a447d1/Segmental-units-in-nonhuman-animal-vocalization-as-a-window-into-meaning-structure-and-the-evolution-of-language.pdf"><strong>Segmental units in nonhuman animal vocalization as a window into meaning, structure, and the evolution of language.</strong></a></p>
<p><strong>Dan C. Mann</strong>, Marisa Hoeschele. <em>Animal Behavior and Cognition.</em> 2020.</p>
<p><strong>Abstract:</strong> Human vocalizations are made up of meaningless units or segments that are combined to create meaningful words and phrases. Jackendoff (1999) hypothesized that the ability of humans to combine segments together is necessitated by the fact that we need to express an almost limitless amount of symbolic or referential information that could occur in a different time or space. So far, there is very little evidence for this symbolic and referentiality meaning in animal vocalizations. Furthermore, segments have also rarely been identified in the animal kingdom, with units divided by intakes of breaths taken as the most fundamental. However, if we are to take Jackendoff’s hypothesis seriously, we must do more detailed analyses at the level of the segment (subunits within a single breath) in animal vocalizations. Here we discuss the current status of animal vocal communication and its relation to Jackendoff’s hypothesis. We propose further research into segmental units in animal vocalizations is a key next step to determining the evolution of human vocal behavior.</p>
</section>
<section id="section-3" class="level2">
<h2 class="anchored" data-anchor-id="section-3">2019</h2>
<p><a href="https://brill.com/view/journals/beh/156/5-8/article-p479_4.xml"><strong>Octave equivalence perception is not linked to vocal mimicry: budgerigars fail standardized operant tests for octave equivalence</strong></a></p>
<p>Bernhard Wagner, <strong>Dan C. Mann</strong>, Shahrzad Afroozeh, Gabriel Staubmann, and Marisa Hoeschele. <em>Behaviour.</em> 2019.</p>
<p><strong>Abstract:</strong> Octave equivalence describes the perceived similarity of notes separated by an octave or a doubling in frequency. In humans, octave equivalence perception is used in vocal learning, enabling young children to approximate adult sounds where the pitch lies outside of their vocal range. This makes sense because the octave is also the first harmonic of any tonal sound including the human voice. We hypothesized that non-human animals may also need octave equivalence perception in vocal mimicry, the copying of other species or environmental sounds, to approximate sounds where the pitch lies outside their vocal range. Thus, in the current study, we tested budgerigars (Melopsittacus undulatus), a vocal mimicking species, for octave equivalence perception. Budgerigars were trained and tested in a go/no-go operant task previously verified in humans. Budgerigars did not show evidence of octave equivalence perception. This result suggests that vocal-mimicking does not necessarily facilitate or presuppose octave equivalence perception.</p>
<p><a href="https://www.researchgate.net/profile/Michael-Pucher-2/publication/335948361_Statistical_parametric_synthesis_of_budgerigar_songs/links/5e15f9f692851c8364bba970/Statistical-parametric-synthesis-of-budgerigar-songs.pdf"><strong>Statistical parametric synthesis of budgerigar songs</strong></a></p>
<p>Lorenz Gutscher, Michael Pucher, Carina Lozo, Marisa Hoeschele, <strong>Daniel C Mann</strong>. <em>Proc. 10th ISCA Speech Synthesis Workshop.</em> 2019.</p>
<p><strong>Abstract</strong>: In this paper we present the synthesis of budgerigar songs with Hidden Markov Models (HMMs) and the HMM-based Speech Synthesis System (HTS). Budgerigars can produce complex and diverse sounds that are difficult to categorize. We adapted techniques that are commonly used in the area of speech synthesis so that we can use them for the synthesis of budgerigar songs. To segment the recordings, the songs are broken down into phrases, which are sounds separated by silence. Complex phrases furthermore can be subdivided into smaller units and then be clustered to identify recurring elements. These element categories along with additional contextual information are used together to enhance the training and synthesis. Overall, the aim of the process is to offer an interface that generates new sequences and compositions of bird songs based on user input, consisting of the desired song structure and contextual information. Finally, an objective evaluation comparing the synthesized output to the natural recording is performed, and a subjective evaluation with human listeners shows that they prefer resynthesized over natural recordings and that they perceive no significant differences in terms of naturalness between natural, resynthesized, and synthesized versions.</p>
</section>
<section id="section-4" class="level2">
<h2 class="anchored" data-anchor-id="section-4">2012</h2>
<p><a href="https://journals.library.columbia.edu/index.php/SALT/article/view/1358/420"><strong>Chilean clitic reduplication: Implications for morphology and syntax</strong></a></p>
<p><strong>Daniel Mann</strong>. <em>Studies in Applied Linguistics and TESOL.</em> 2012.</p>
<p><strong>Abstract</strong>: This paper explores the phenomenon of clitic duplication in Spanish as seen in the sentence Te voy a pegarte (‘I’m going to hit you’). Structures like these have several interesting implications for the Spanish language and generativist syntax. Neverthelesss, clitic duplication has not been extensively examined in the generativist literature. This working paper will critically review the small body of existing work on clitic reduplication. Furthermore, based on data gathered from native speakers of Chilean Spanish, it will provide some preliminary evidence for strengthening the argument that Spanish clitics are object agreement morphemes. Ultimately, this paper aims to provide a base to further pursue the topic of Chilean clitic reduplication to make more theoretically sound claims, provide more robust empirical data, and to propose a more formalized argument of the phenomena. Pedagogical implications of the argument are also considered.</p>


</section>

</main> <!-- /main -->
<script id="quarto-html-after-body" type="application/javascript">
window.document.addEventListener("DOMContentLoaded", function (event) {
  const toggleBodyColorMode = (bsSheetEl) => {
    const mode = bsSheetEl.getAttribute("data-mode");
    const bodyEl = window.document.querySelector("body");
    if (mode === "dark") {
      bodyEl.classList.add("quarto-dark");
      bodyEl.classList.remove("quarto-light");
    } else {
      bodyEl.classList.add("quarto-light");
      bodyEl.classList.remove("quarto-dark");
    }
  }
  const toggleBodyColorPrimary = () => {
    const bsSheetEl = window.document.querySelector("link#quarto-bootstrap");
    if (bsSheetEl) {
      toggleBodyColorMode(bsSheetEl);
    }
  }
  toggleBodyColorPrimary();  
  const icon = "";
  const anchorJS = new window.AnchorJS();
  anchorJS.options = {
    placement: 'right',
    icon: icon
  };
  anchorJS.add('.anchored');
  const clipboard = new window.ClipboardJS('.code-copy-button', {
    target: function(trigger) {
      return trigger.previousElementSibling;
    }
  });
  clipboard.on('success', function(e) {
    // button target
    const button = e.trigger;
    // don't keep focus
    button.blur();
    // flash "checked"
    button.classList.add('code-copy-button-checked');
    var currentTitle = button.getAttribute("title");
    button.setAttribute("title", "Copied!");
    let tooltip;
    if (window.bootstrap) {
      button.setAttribute("data-bs-toggle", "tooltip");
      button.setAttribute("data-bs-placement", "left");
      button.setAttribute("data-bs-title", "Copied!");
      tooltip = new bootstrap.Tooltip(button, 
        { trigger: "manual", 
          customClass: "code-copy-button-tooltip",
          offset: [0, -8]});
      tooltip.show();    
    }
    setTimeout(function() {
      if (tooltip) {
        tooltip.hide();
        button.removeAttribute("data-bs-title");
        button.removeAttribute("data-bs-toggle");
        button.removeAttribute("data-bs-placement");
      }
      button.setAttribute("title", currentTitle);
      button.classList.remove('code-copy-button-checked');
    }, 1000);
    // clear code selection
    e.clearSelection();
  });
  function tippyHover(el, contentFn) {
    const config = {
      allowHTML: true,
      content: contentFn,
      maxWidth: 500,
      delay: 100,
      arrow: false,
      appendTo: function(el) {
          return el.parentElement;
      },
      interactive: true,
      interactiveBorder: 10,
      theme: 'quarto',
      placement: 'bottom-start'
    };
    window.tippy(el, config); 
  }
  const noterefs = window.document.querySelectorAll('a[role="doc-noteref"]');
  for (var i=0; i<noterefs.length; i++) {
    const ref = noterefs[i];
    tippyHover(ref, function() {
      // use id or data attribute instead here
      let href = ref.getAttribute('data-footnote-href') || ref.getAttribute('href');
      try { href = new URL(href).hash; } catch {}
      const id = href.replace(/^#\/?/, "");
      const note = window.document.getElementById(id);
      return note.innerHTML;
    });
  }
  const findCites = (el) => {
    const parentEl = el.parentElement;
    if (parentEl) {
      const cites = parentEl.dataset.cites;
      if (cites) {
        return {
          el,
          cites: cites.split(' ')
        };
      } else {
        return findCites(el.parentElement)
      }
    } else {
      return undefined;
    }
  };
  var bibliorefs = window.document.querySelectorAll('a[role="doc-biblioref"]');
  for (var i=0; i<bibliorefs.length; i++) {
    const ref = bibliorefs[i];
    const citeInfo = findCites(ref);
    if (citeInfo) {
      tippyHover(citeInfo.el, function() {
        var popup = window.document.createElement('div');
        citeInfo.cites.forEach(function(cite) {
          var citeDiv = window.document.createElement('div');
          citeDiv.classList.add('hanging-indent');
          citeDiv.classList.add('csl-entry');
          var biblioDiv = window.document.getElementById('ref-' + cite);
          if (biblioDiv) {
            citeDiv.innerHTML = biblioDiv.innerHTML;
          }
          popup.appendChild(citeDiv);
        });
        return popup.innerHTML;
      });
    }
  }
});
</script>
</div> <!-- /content -->
<footer class="footer">
  <div class="nav-footer">
    <div class="nav-footer-left">Copyright 2023, Dan C. Mann</div>   
    <div class="nav-footer-right">
      <ul class="footer-items list-unstyled">
    <li class="nav-item compact">
    <a class="nav-link" href="https://github.com/dancmann/">
      <i class="bi bi-github" role="img">
</i> 
    </a>
  </li>  
</ul>
    </div>
  </div>
</footer>



</body></html>